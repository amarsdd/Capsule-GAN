{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers, models\n",
    "from keras import losses\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "\n",
    "# visualization\n",
    "import skimage\n",
    "from skimage import data, color, exposure\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# sys and helpers\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVISE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('Modules imported.')\n",
    "\n",
    "\n",
    "\n",
    "datasets = 'mnist'\n",
    "\n",
    "if datasets=='mnist':\n",
    "    img_rows = 28\n",
    "    img_cols = 28\n",
    "    channels = 1\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "elif datasets=='cifar10':\n",
    "    img_rows = 32\n",
    "    img_cols = 32\n",
    "    channels = 3\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "    \n",
    "num_classes = 10\n",
    "latent_dim = 100\n",
    "routings = 3\n",
    "# # device check\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print('Devices:', device_lib.list_local_devices())\n",
    "\n",
    "# # GPU check\n",
    "# if not tf.test.gpu_device_name():\n",
    "#     print('No GPU found.')\n",
    "# else:\n",
    "#     print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Margin Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# discriminator structure\n",
    "def build_discriminator():\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "#         x = UpSampling2D()(x)\n",
    "#     x = Conv2D(128, kernel_size=3, strides=1, padding=\"same\")(img)\n",
    "#     x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(256, kernel_size=9, strides=1, padding=\"valid\")(img)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = PrimaryCap(x, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "    x = CapsuleLayer(num_capsule=10, dim_capsule=32, routings=routings)(x)\n",
    "#         x = Mask()(x)\n",
    "#     y = layers.Input(shape=(num_classes+1,))\n",
    "#     x2 = Mask()([x, y])\n",
    "# #     x2 = Length(name='capsnet')(x)\n",
    "#     x1 = Mask()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Determine validity and label of the image\n",
    "    validity = Dense(1, activation=\"sigmoid\", name='ds')(x)\n",
    "    label = Dense(num_classes, activation=\"softmax\", name='label')(x)\n",
    "\n",
    "    return Model(img, [validity, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0002, 0.5)\n",
    "losses1 = ['binary_crossentropy', 'categorical_crossentropy']\n",
    "# losses1 =[]\n",
    "# losses1.append(losses.binary_crossentropy)\n",
    "# losses1.append(margin_loss)\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "print('DISCRIMINATOR:')\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator.compile(loss=losses1, optimizer=optimizer, metrics={'label':'accuracy', 'ds':'accuracy'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# generator structure\n",
    "def build_generator():\n",
    "\n",
    "    \"\"\"\n",
    "    Generator follows the DCGAN architecture and creates generated image representations through learning.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # we apply different kernel sizes in order to match the original image size\n",
    "    \n",
    "    if datasets=='mnist':\n",
    "#         noise = Input(shape=(latent_dim,))\n",
    "#         label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "#         label_embedding = Flatten()(Embedding(num_classes, 100)(label))\n",
    "\n",
    "#         model_input = multiply([noise, label_embedding])\n",
    "\n",
    "#         x = Dense(14 * 14 * 1, activation=\"relu\")(model_input)\n",
    "#         x = Reshape((14, 14, 1))(x)\n",
    "#         x = BatchNormalization(momentum=0.8)(x)\n",
    "#         x = UpSampling2D()(x)\n",
    "#         x = Conv2D(64, kernel_size=9, strides=1, padding=\"valid\")(x)\n",
    "#         x = LeakyReLU(alpha=0.2)(x)\n",
    "#         x = BatchNormalization(momentum=0.8)(x)\n",
    "# #         x = UpSampling2D()(x)\n",
    "# #         x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "# #         x = LeakyReLU(alpha=0.2)(x)\n",
    "# #         x = BatchNormalization(momentum=0.8)(x)\n",
    "#         x = PrimaryCap(x, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "#         x = CapsuleLayer(num_capsule=10, dim_capsule=98, routings=routings)(x)\n",
    "# #         x = Mask()(x)\n",
    "# #         y = layers.Input(shape=(num_classes,))\n",
    "# #         x = Mask()([x, y])\n",
    "#         x = Flatten()(x)\n",
    "\n",
    "#         x = Reshape((7, 7, 20))(x)\n",
    "#         x = BatchNormalization(momentum=0.8)(x)\n",
    "#         x = UpSampling2D()(x)\n",
    "#         x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
    "#         x = LeakyReLU(alpha=0.2)(x)\n",
    "#         x = BatchNormalization(momentum=0.8)(x)\n",
    "#         x = UpSampling2D()(x)\n",
    "#         x = Conv2D(channels, kernel_size=3, padding=\"same\")(x)\n",
    "#         img = Activation(\"tanh\")(x)\n",
    "        \n",
    "#         return Model([noise, label], img)\n",
    "#         return Model([noise, y], img)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(512, kernel_size=3, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(channels, kernel_size=3, padding='same'))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(num_classes, 100)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "\n",
    "        \n",
    "    if datasets=='cifar10':\n",
    "#         noise = Input(shape=(latent_dim,))\n",
    "#         label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "#         label_embedding = Flatten()(Embedding(num_classes, 100)(label))\n",
    "\n",
    "#         model_input = multiply([noise, label_embedding])\n",
    "\n",
    "#         x = Dense(16 * 16 * 1, activation=\"relu\")(model_input)\n",
    "#         x = Reshape((16, 16, 1))(x)\n",
    "#         x = BatchNormalization(momentum=0.8)(x)\n",
    "#         x = UpSampling2D()(x)\n",
    "#         x = Conv2D(64, kernel_size=9, strides=1, padding=\"valid\")(x)\n",
    "#         x = LeakyReLU(alpha=0.2)(x)\n",
    "#         x = BatchNormalization(momentum=0.8)(x)\n",
    "# #         x = UpSampling2D()(x)\n",
    "# #         x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "# #         x = LeakyReLU(alpha=0.2)(x)\n",
    "# #         x = BatchNormalization(momentum=0.8)(x)\n",
    "#         x = PrimaryCap(x, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "#         x = CapsuleLayer(num_capsule=10, dim_capsule=64, routings=routings)(x)\n",
    "# #         x = Mask()(x)\n",
    "# #         y = layers.Input(shape=(num_classes,))\n",
    "# #         x = Mask()([x, y])\n",
    "#         x = Flatten()(x)\n",
    "\n",
    "#         x = Reshape((8, 8, 10))(x)\n",
    "#         x = BatchNormalization(momentum=0.8)(x)\n",
    "#         x = UpSampling2D()(x)\n",
    "#         x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
    "#         x = LeakyReLU(alpha=0.2)(x)\n",
    "#         x = BatchNormalization(momentum=0.8)(x)\n",
    "#         x = UpSampling2D()(x)\n",
    "#         x = Conv2D(channels, kernel_size=3, padding=\"same\")(x)\n",
    "#         img = Activation(\"tanh\")(x)\n",
    "        \n",
    "#         return Model([noise, label], img)\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(512, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(channels, kernel_size=3, padding='same'))\n",
    "\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(num_classes, 100)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the generator\n",
    "generator = build_generator()\n",
    "print('GENERATOR:')\n",
    "generator.summary()\n",
    "# The generator takes noise and the target label as input\n",
    "# and generates the corresponding digit of that label\n",
    "noise = Input(shape=(latent_dim,))\n",
    "label = Input(shape=(1,))\n",
    "\n",
    "img = generator([noise, label])\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator takes generated image as input and determines validity\n",
    "# and the label of that image\n",
    "valid, target_label = discriminator(img)\n",
    "\n",
    "# The combined model  (stacked generator and discriminator) takes\n",
    "# noise as input => generates images => determines validity\n",
    "combined = Model([noise, label], [valid, target_label])\n",
    "combined.compile(loss=losses1, optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loss values for further plotting\n",
    "D_L_REAL = []\n",
    "D_L_FAKE = []\n",
    "D_L = []\n",
    "D_ACC = []\n",
    "G_L = []\n",
    "Class_Acc = []\n",
    "sample_z = []\n",
    "pdf_x = []\n",
    "fake_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "    # Load the dataset\n",
    "    if dataset=='mnist':\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "    elif dataset=='cifar10':\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "#         X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "#         X_test = np.expand_dims(X_test, axis=3)\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "#     # Rescale -1 to 1\n",
    "#     X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "#     X_train = np.expand_dims(X_train, axis=3)\n",
    "#     y_train = y_train.reshape(-1, 1)\n",
    "    \n",
    "#     X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "#     X_test = np.expand_dims(X_test, axis=3)\n",
    "#     y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "\n",
    "    ## Pre-train\n",
    "    valid = np.ones((60000,1))\n",
    "    y_tr = to_categorical(y_train, num_classes=num_classes)\n",
    "    discriminator.fit(x=X_train, y=[valid, y_tr], batch_size=128, epochs=1)\n",
    "    discriminator.save_weights('saved_model'+ '/trained_'+datasets+'_capsdiscriminator_1epoch_10class.h5')\n",
    "#     discriminator.load_weights('saved_model'+ '/trained_discriminator_cur_1epoch_10class2.h5')\n",
    "\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "        # The labels of the digits that the generator tries to create an\n",
    "        # image representation of\n",
    "        sampled_labels = np.random.randint(0, 10, half_batch).reshape(-1, 1)\n",
    "#         sampled_labels = to_categorical(sampled_labels, num_classes=num_classes)\n",
    "        \n",
    "        # Generate a half batch of new images\n",
    "        gen_imgs = generator.predict([noise, sampled_labels])\n",
    "#         valid = np.ones((half_batch, 1))\n",
    "#         fake = np.zeros((half_batch, 1))\n",
    "        \n",
    "        valid = np.random.uniform(0.7,1.2,(half_batch,1))\n",
    "        fake = np.random.uniform(0.0,0.3,(half_batch,1))\n",
    "            \n",
    "        # Image labels. 0-9 if image is valid or 10 if it is generated (fake)\n",
    "        img_labels = y_train[idx]\n",
    "        img_labels1 = to_categorical(img_labels, num_classes=num_classes)\n",
    "        img_l = np.random.uniform(0.7,1.0,img_labels1.shape)\n",
    "        img_labels2 = np.multiply(img_labels1, img_l)\n",
    "        \n",
    "        fake_labels = np.zeros((half_batch, num_classes))\n",
    "#         fake_labels = sampled_labels\n",
    "#         fake_labels1 = to_categorical(fake_labels, num_classes=num_classes)\n",
    "#         fake_l = np.random.uniform(0.7, 1.0,fake_labels1.shape)\n",
    "#         fake_labels2 = np.multiply(fake_labels1, fake_l)\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = discriminator.train_on_batch([imgs], [valid, img_labels2])\n",
    "        d_loss_fake = discriminator.train_on_batch([gen_imgs], [fake, fake_labels])\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        ft = 1\n",
    "        # Sample generator input\n",
    "        noise = np.random.normal(0, 1, (batch_size*ft, 100))\n",
    "        valid = np.ones((batch_size*ft, 1))\n",
    "        # Generator wants discriminator to label the generated images as the intended\n",
    "        # digits\n",
    "        sampled_labels = np.random.randint(0, 10, batch_size*ft).reshape(-1, 1)\n",
    "        sampled_labels1 = to_categorical(sampled_labels, num_classes=num_classes)\n",
    "#         sampled_labels = to_categorical(sampled_labels, num_classes=num_classes)\n",
    "\n",
    "        # Train the generator\n",
    "        g_loss = combined.train_on_batch([noise, sampled_labels], [valid, sampled_labels1])\n",
    "\n",
    "        # Plot the progress\n",
    "        print (\"%d %s %s %s %s %s\" %(epoch, discriminator.metrics_names[0], discriminator.metrics_names[1], discriminator.metrics_names[2], discriminator.metrics_names[3], discriminator.metrics_names[4]))\n",
    "        print (\"   %f %f %f %.2f %.2f\" % (d_loss[0], d_loss[1], d_loss[2], d_loss[3], d_loss[4]))\n",
    "#         print (\"%d [D loss: %f, acc.: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss[0]))\n",
    "# #         print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "#         print (\"%d [D_real loss: %f, acc.: %.2f%%]\" % (epoch, d_loss_real[0], 100*d_loss_real[1]))\n",
    "#         print (\"%d [D_fake loss: %f, acc.: %.2f%%]\" % (epoch, d_loss_fake[0], 100*d_loss_fake[1]))\n",
    "        D_L_REAL.append(d_loss_real)\n",
    "        D_L_FAKE.append(d_loss_fake)\n",
    "        D_L.append(d_loss)\n",
    "        D_ACC.append(d_loss[1])\n",
    "        G_L.append(g_loss)\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % sample_interval == 0:\n",
    "            save_model()\n",
    "            sample_images(epoch)\n",
    "            \n",
    "            valid1 = np.ones((y_test.size, 1))\n",
    "\n",
    "            img_labels1 = y_test\n",
    "            img_labels1 = to_categorical(img_labels1, num_classes=num_classes)\n",
    "\n",
    "            # test the discriminator\n",
    "#             discriminator.trainable = False\n",
    "#             discriminator.save_weights('saved_model'+ '/trained_discriminator_cur.h5')\n",
    "#             discriminator_eval.load_weights('saved_model'+ '/trained_discriminator_cur.h5')\n",
    "            test_acc = discriminator.evaluate(X_test, [valid1, img_labels1])\n",
    "#             discriminator.trainable = True\n",
    "#             print(test_acc)\n",
    "            print(\"Test Accuracy = %.2f \" %(test_acc[4]*100))\n",
    "            Class_Acc.append(test_acc[4])\n",
    "        \n",
    "#             tst = 5000\n",
    "#             valid = np.ones((tst,1))\n",
    "#             idx = np.random.randint(0, X_train.shape[0], tst)\n",
    "#             imgs = X_train[idx]\n",
    "#             y_imgs = y_train[idx]\n",
    "#             y_tr = to_categorical(y_imgs, num_classes=num_classes)\n",
    "#             discriminator.fit(x=imgs, y=[valid, y_tr], batch_size=128, epochs=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sample_images(epoch):\n",
    "    r, c = 5, 10\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "#     sampled_labels = to_categorical(sampled_labels, num_classes=num_classes)\n",
    "    gen_imgs = generator.predict([noise, sampled_labels])\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if datasets == 'mnist':\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "            elif datasets == 'cifar10':\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "    fig.savefig(\"images_Dcaps_%s/%d.png\" % (datasets,epoch))\n",
    "    plt.close()\n",
    "\n",
    "def save_model():\n",
    "\n",
    "    def save(model, model_name):\n",
    "        model_path = \"saved_model/%s.json\" % model_name\n",
    "        weights_path = \"saved_model/%s_weights.hdf5\" % model_name\n",
    "        options = {\"file_arch\": model_path,\n",
    "                        \"file_weight\": weights_path}\n",
    "        json_string = model.to_json()\n",
    "        open(options['file_arch'], 'w').write(json_string)\n",
    "        model.save_weights(options['file_weight'])\n",
    "    \n",
    "    save(generator, datasets+\"_capsDgan_generator\")\n",
    "    save(discriminator, datasets+\"_capsDgan_discriminator\")\n",
    "    save(combined, datasets+\"_capsDgan_adversarial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = train(datasets, epochs=5000, batch_size=32, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "discriminator.trainable\n",
    "\n",
    "np.savez(datasets+'capsDgan.npz',Class_Acc=Class_Acc, D_L=D_L, G_L=G_L, D_L_REAL=D_L_REAL, D_L_FAKE=D_L_FAKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tmp_rdl = []\n",
    "tmp_fdl = []\n",
    "tmp_gl = []\n",
    "tmp_n = np.size(D_L)/2\n",
    "tmp_n = 4000\n",
    "for i in range(tmp_n):\n",
    "    tmp_rdl.append(D_L_REAL[i][0])\n",
    "    tmp_fdl.append(D_L_FAKE[i][0])\n",
    "    tmp_gl.append(G_L[i][0])\n",
    "    \n",
    "# fig, ax = plt.figure()\n",
    "plt.plot(tmp_rdl)\n",
    "plt.plot(tmp_fdl)\n",
    "plt.plot(tmp_gl)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Discriminator Real Loss','Discriminator Fake Loss', 'Generator Loss'])\n",
    "plt.savefig(datasets+'capsDgan_all_loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.figure()\n",
    "plt.plot(Class_Acc)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig(datasets+'capsDgan_Classification_Accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "num_samps = 500\n",
    "if datasets=='mnist':\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "        # Select a random half batch of images\n",
    "    idx = np.random.randint(0, X_train.shape[0], num_samps)\n",
    "    imgs = X_train[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (num_samps, 100))\n",
    "\n",
    "            # The labels of the digits that the generator tries to create an\n",
    "            # image representation of\n",
    "    sampled_labels = np.random.randint(0, 10, num_samps).reshape(-1, 1)\n",
    "#     sampled_labels = to_categorical(sampled_labels, num_classes=num_classes)\n",
    "            # Generate a half batch of new images\n",
    "    gen_imgs = generator.predict([noise, sampled_labels])\n",
    "\n",
    "    # idx = np.random.randint(0, dataset.shape[0], 1000)\n",
    "    # pdf_x = dataset[idx]\n",
    "    pdf_x = imgs.reshape([-1, 28*28])\n",
    "    sample_z = noise\n",
    "    fake_pred = gen_imgs.reshape([-1, 28*28])\n",
    "\n",
    "    generator1 = build_generator()\n",
    "    generator1.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "    fake_pred_i  = generator1.predict([noise, sampled_labels])\n",
    "    fake_pred_i = fake_pred_i.reshape([-1, 28*28])\n",
    "\n",
    "    t0 = TSNE(n_components=2).fit_transform(fake_pred_i)\n",
    "    t1 = TSNE(n_components=2).fit_transform(pdf_x)\n",
    "    t2 = TSNE(n_components=2).fit_transform(fake_pred)\n",
    "\n",
    "\n",
    "    _ = plt.scatter(t1[:,0], t1[:,1], edgecolor='none')\n",
    "    _ = plt.scatter(t2[:,0], t2[:,1], color='green', edgecolor='none')\n",
    "    _ = plt.scatter(t0[:,0], t0[:,1], edgecolor='none', color='orange')\n",
    "    plt.legend(['Actual data', 'Generated data', 'Initially Generated data'])\n",
    "    plt.savefig(datasets+'capsDgan_all_distributions.png')\n",
    "    plt.show()\n",
    "\n",
    "elif datasets=='cifar10':\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "        # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "#         X_train = np.expand_dims(X_train, axis=3)\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    # Select a random half batch of images\n",
    "    idx = np.random.randint(0, X_train.shape[0], num_samps)\n",
    "    imgs = X_train[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (num_samps, 100))\n",
    "\n",
    "            # The labels of the digits that the generator tries to create an\n",
    "            # image representation of\n",
    "    sampled_labels = np.random.randint(0, 10, num_samps).reshape(-1, 1)\n",
    "#     sampled_labels = to_categorical(sampled_labels, num_classes=num_classes)\n",
    "            # Generate a half batch of new images\n",
    "    gen_imgs = generator.predict([noise, sampled_labels])\n",
    "\n",
    "    # idx = np.random.randint(0, dataset.shape[0], 1000)\n",
    "    # pdf_x = dataset[idx]\n",
    "    pdf_x = imgs.reshape([-1, 32*32*3])\n",
    "    sample_z = noise\n",
    "    fake_pred = gen_imgs.reshape([-1, 32*32*3])\n",
    "\n",
    "    generator1 = build_generator()\n",
    "    generator1.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "    fake_pred_i  = generator1.predict([noise, sampled_labels])\n",
    "    fake_pred_i = fake_pred_i.reshape([-1, 32*32*3])\n",
    "\n",
    "    t0 = TSNE(n_components=2).fit_transform(fake_pred_i)\n",
    "    t1 = TSNE(n_components=2).fit_transform(pdf_x)\n",
    "    t2 = TSNE(n_components=2).fit_transform(fake_pred)\n",
    "\n",
    "\n",
    "    _ = plt.scatter(t1[:,0], t1[:,1], edgecolor='none')\n",
    "    _ = plt.scatter(t2[:,0], t2[:,1], color='green', edgecolor='none')\n",
    "    _ = plt.scatter(t0[:,0], t0[:,1], edgecolor='none', color='orange')\n",
    "    plt.legend(['Actual data', 'Generated data', 'Initially Generated data'])\n",
    "    plt.savefig(datasets+'capsDgan_all_distributions.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
